{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "### YAML Configugarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nname: volume_forecast_oreilly\\ndependencies:\\n  - python\\n  - matplotlib\\n  - mxnet \\n  - numpy\\n  - pandas\\n  - scipy\\n  - ipykernel\\n  - openpyxl \\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "## YAML Configugarion\n",
    "################################################\n",
    "\"\"\"\n",
    "name: volume_forecast_oreilly\n",
    "dependencies:\n",
    "  - python\n",
    "  - matplotlib\n",
    "  - mxnet \n",
    "  - numpy\n",
    "  - pandas\n",
    "  - scipy\n",
    "  - ipykernel\n",
    "  - openpyxl \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "width = 6\n",
    "height = 3\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## utilities\n",
    "import os\n",
    "\n",
    "## deep learning module\n",
    "import mxnet as mx\n",
    "\n",
    "## data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## reporting\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some hyperparameters we won't tune via command line inputs\n",
    "DATA_SEGMENTS    = { 'tr': 0.6, 'va': 0.2, 'tst': 0.2}\n",
    "THRESHOLD_EPOCHS = 2\n",
    "COR_THRESHOLD    =  0.005\n",
    "\n",
    "## temporal slicing\n",
    "WIN              = 24 * 7\n",
    "H                = 8\n",
    "\n",
    "## model details \n",
    "MODEL            = 'simple_lstnet_model'\n",
    "# MODEL            = 'fc_model' # not working\n",
    "# MODEL            = 'rnn_model'\n",
    "# MODEL            = 'cnn_model' # not working\n",
    "SZ_FILT          = 8\n",
    "N_FILT           = 10\n",
    "RNN_UNITS        = 10\n",
    "SEASONAL_PERIOD  = 24\n",
    "\n",
    "## training details\n",
    "GPU              = 0\n",
    "BATCH_N          = 64\n",
    "LR               = 0.0001\n",
    "DROP             = 0.2\n",
    "N_EPOCHS         = 300\n",
    "\n",
    "## data details\n",
    "# SHEET_NAME       = 'CC'\n",
    "SHEET_NAME       = 'HTU'\n",
    "DATA_FILE_DIR    = r'C:/Users/mjonkus/Philip Morris International/Finance Advanced Analytics - Finance - Global - General/03. Projects/4. IMS Forecasting/'\n",
    "DATA_FILE_NAME   = 'Daily IMS.xlsx'\n",
    "DATA_FILE        = DATA_FILE_DIR + DATA_FILE_NAME\n",
    "SAVE_DIR         = \"./IMS_NN_resultsDir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PMI                float64\n",
       "HEETS AMBER        float64\n",
       "HEETS BLUE         float64\n",
       "HEETS BRONZE       float64\n",
       "HEETS SIENNA       float64\n",
       "HEETS TEAK         float64\n",
       "HEETS TURQUOISE    float64\n",
       "HEETS YELLOW       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htu_IMS_raw = pd.read_excel(DATA_FILE,sheet_name=SHEET_NAME,engine='openpyxl')\n",
    "htu_IMS = htu_IMS_raw\n",
    "# htu_IMS = htu_IMS_raw.iloc[:,1:9]\n",
    "# htu_IMS.columns = ['time_stamp','HTU_IMS']\n",
    "# htu_IMS['Row.Labels'] = pd.to_datetime(htu_IMS['Row.Labels'])\n",
    "htu_IMS = htu_IMS.set_index('Row.Labels',drop=True) \n",
    "\n",
    "htu_IMS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMI</th>\n",
       "      <th>HEETS AMBER</th>\n",
       "      <th>HEETS BLUE</th>\n",
       "      <th>HEETS BRONZE</th>\n",
       "      <th>HEETS SIENNA</th>\n",
       "      <th>HEETS TEAK</th>\n",
       "      <th>HEETS TURQUOISE</th>\n",
       "      <th>HEETS YELLOW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row.Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>19055.5</td>\n",
       "      <td>3351.55</td>\n",
       "      <td>1754.6</td>\n",
       "      <td>2412.6</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>3252.6</td>\n",
       "      <td>2783.95</td>\n",
       "      <td>3051.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>20067.8</td>\n",
       "      <td>3455.20</td>\n",
       "      <td>1865.6</td>\n",
       "      <td>2529.2</td>\n",
       "      <td>2633.4</td>\n",
       "      <td>3509.6</td>\n",
       "      <td>2916.20</td>\n",
       "      <td>3158.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>4626.8</td>\n",
       "      <td>774.20</td>\n",
       "      <td>459.0</td>\n",
       "      <td>618.6</td>\n",
       "      <td>576.8</td>\n",
       "      <td>764.2</td>\n",
       "      <td>692.60</td>\n",
       "      <td>741.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PMI  HEETS AMBER  HEETS BLUE  HEETS BRONZE  HEETS SIENNA  \\\n",
       "Row.Labels                                                                 \n",
       "2020-01-02  19055.5      3351.55      1754.6        2412.6        2449.0   \n",
       "2020-01-03  20067.8      3455.20      1865.6        2529.2        2633.4   \n",
       "2020-01-04   4626.8       774.20       459.0         618.6         576.8   \n",
       "2020-01-05      0.0         0.00         0.0           0.0           0.0   \n",
       "2020-01-06      0.0         0.00         0.0           0.0           0.0   \n",
       "\n",
       "            HEETS TEAK  HEETS TURQUOISE  HEETS YELLOW  \n",
       "Row.Labels                                             \n",
       "2020-01-02      3252.6          2783.95        3051.2  \n",
       "2020-01-03      3509.6          2916.20        3158.6  \n",
       "2020-01-04       764.2           692.60         741.4  \n",
       "2020-01-05         0.0             0.00           0.0  \n",
       "2020-01-06         0.0             0.00           0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= htu_IMS.resample('D').asfreq().fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PMI                float64\n",
       "HEETS AMBER        float64\n",
       "HEETS BLUE         float64\n",
       "HEETS BRONZE       float64\n",
       "HEETS SIENNA       float64\n",
       "HEETS TEAK         float64\n",
       "HEETS TURQUOISE    float64\n",
       "HEETS YELLOW       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator to resample time series and fill in with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator to resample time series and fill in with 0\n",
    "\n",
    "def generate_missing_dates (df):\n",
    "    df_generated= df.resample('D').asfreq().fillna(0)\n",
    "    return df_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring bufffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RingBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.data = [0 for i in range(size)]\n",
    "\n",
    "    def append(self, x):\n",
    "        self.data.pop(0)\n",
    "        self.data.append(x)\n",
    "\n",
    "    def get(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## DATA PREPARATION ##\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "def prepared_data(data_file, win, h, model_name):\n",
    "    df = pd.read_excel(data_file,sheet_name=SHEET_NAME,engine='openpyxl')\n",
    "    df = df.set_index('Row.Labels',drop=True) \n",
    "    df = generate_missing_dates(df)\n",
    "    x  = df.iloc[:,1:8].values ## need to drop first column as that's an index not a value and keep only total PMI\n",
    "    x = (x - np.mean(x, axis = 0)) / (np.std(x, axis = 0)) ## normalize data\n",
    "    \n",
    "    if model_name == 'fc_model':\n",
    "        ## provide first and second step lookbacks in one flat input\n",
    "        X = np.hstack([x[1:-h], x[0:-(h+1)]])\n",
    "        Y = x[(h+1):]\n",
    "        return (X, Y)\n",
    "    else:    \n",
    "        # preallocate X and Y data arrays\n",
    "        # X shape = num examples * time win * num channels (NTC)\n",
    "        X = np.zeros((x.shape[0] - win - h, win, x.shape[1]))\n",
    "        # Y shape = num examples * num channels\n",
    "        Y = np.zeros((x.shape[0] - win - h, x.shape[1]))\n",
    "        \n",
    "        for i in range(win, x.shape[0] - h):\n",
    "            y_i = x[i + h - 1     , :] ## the target value is h steps ahead\n",
    "            x_i = x[(i - win) : i , :] ## the input data are the previous win steps\n",
    "            X[i-win] = x_i\n",
    "            Y[i-win] = y_i\n",
    "\n",
    "        return (X, Y)\n",
    "\n",
    "\n",
    "def prepare_iters(data_file, win, h, model, batch_n):\n",
    "    X, Y = prepared_data(data_file, win, h, model)\n",
    "\n",
    "    n_tr = int(Y.shape[0] * DATA_SEGMENTS['tr'])\n",
    "    n_va = int(Y.shape[0] * DATA_SEGMENTS['va'])\n",
    "\n",
    "    X_tr, X_valid, X_test = X[                 : n_tr], \\\n",
    "                            X[n_tr             : n_tr + n_va], \\\n",
    "                            X[n_tr + n_va : ]\n",
    "    Y_tr, Y_valid, Y_test = Y[                 : n_tr], \\\n",
    "                            Y[n_tr             : n_tr + n_va], \\\n",
    "                            Y[n_tr + n_va : ]\n",
    "    \n",
    "    iter_tr = mx.io.NDArrayIter(   data       = X_tr,\n",
    "                                   label      = Y_tr,\n",
    "                                   batch_size = batch_n)\n",
    "    iter_val = mx.io.NDArrayIter(  data       = X_valid,\n",
    "                                   label      = Y_valid,\n",
    "                                   batch_size = batch_n)\n",
    "    iter_test = mx.io.NDArrayIter( data       = X_test,\n",
    "                                   label      = Y_test,\n",
    "                                   batch_size = batch_n)\n",
    "\n",
    "    return (iter_tr, iter_val, iter_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model part\n",
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## MODELS ##\n",
    "################\n",
    "\n",
    "def fc_model(iter_train, input_feature_shape, X, Y,\n",
    "             win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    output = mx.sym.FullyConnected(data=X, num_hidden=20)\n",
    "    output = mx.sym.Activation(output, act_type = 'relu')\n",
    "    output = mx.sym.FullyConnected(data=output, num_hidden=10)\n",
    "    output = mx.sym.Activation(output, act_type = 'relu')\n",
    "    output = mx.sym.FullyConnected(data=output, num_hidden=7)\n",
    "    \n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])    \n",
    "    \n",
    "def cnn_model(iter_train, input_feature_shape, X, Y,\n",
    "              win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    conv_input = mx.sym.reshape(data=X, shape=(0, 1, win, -1)) \n",
    "    ## Convolution expects 4d input (N x channel x height x width)\n",
    "    ## in our case channel = 1 (similar to a black and white image\n",
    "    ## height = time and width = channels slash electric locations\n",
    "    \n",
    "    cnn_output = mx.sym.Convolution(data=conv_input,\n",
    "                                    kernel=(sz_filt,\n",
    "                                            input_feature_shape[2]),\n",
    "                                    num_filter=n_filter)\n",
    "    cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "    cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output,\n",
    "                                                 axes=(0, 2, 1, 3)),\n",
    "                                shape=(0, 0, 0)) \n",
    "    cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "        \n",
    "    output = mx.sym.FullyConnected(data=cnn_output,\n",
    "                                   num_hidden=input_feature_shape[2])\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])    \n",
    "\n",
    "    \n",
    "def rnn_model(iter_train, input_feature_shape, X, Y,\n",
    "              win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "    rnn_cells.add(mx.rnn.GRUCell(num_hidden=RNN_UNITS))\n",
    "    rnn_cells.add(mx.rnn.DropoutCell(drop))\n",
    "    outputs, _ = rnn_cells.unroll(length=win, inputs=X, merge_outputs=False)\n",
    "    rnn_output = outputs[-1] # only take value from final unrolled cell for use later\n",
    "    \n",
    "    output = mx.sym.FullyConnected(data=rnn_output, num_hidden=input_feature_shape[2])\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])    \n",
    "\n",
    "## simplifications to\n",
    "## https://github.com/apache/incubator-mxnet/blob/master/example/multivariate_time_series/src/lstnet.py\n",
    "def simple_lstnet_model(iter_train,  input_feature_shape, X, Y,\n",
    "                        win, sz_filt, n_filter, drop, seasonal_period):\n",
    "    ## must be 4d or 5d to use padding functionality\n",
    "    conv_input = mx.sym.reshape(data=X, shape=(0, 1, win, -1)) \n",
    "\n",
    "    ## convolutional element\n",
    "    ## we add padding at the end of the time win\n",
    "    cnn_output = mx.sym.pad(data=conv_input,\n",
    "                            mode=\"constant\",\n",
    "                            constant_value=0,\n",
    "                            pad_width=(0, 0,\n",
    "                                       0, 0,\n",
    "                                       0, sz_filt - 1, \n",
    "                                       0, 0))\n",
    "    cnn_output = mx.sym.Convolution(data=cnn_output,\n",
    "                                    kernel=(sz_filt,\n",
    "                                            input_feature_shape[2]),\n",
    "                                    num_filter=n_filter)\n",
    "    cnn_output = mx.sym.Activation(data=cnn_output, act_type='relu')\n",
    "    cnn_output = mx.sym.reshape(mx.sym.transpose(data=cnn_output,\n",
    "                                                 axes=(0, 2, 1, 3)),\n",
    "                                shape=(0, 0, 0))\n",
    "    cnn_output = mx.sym.Dropout(cnn_output, p=drop)\n",
    "\n",
    "    ## recurrent element\n",
    "    stacked_rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "    stacked_rnn_cells.add(mx.rnn.GRUCell(num_hidden=RNN_UNITS))\n",
    "    outputs, _ = stacked_rnn_cells.unroll(length=win,\n",
    "                                          inputs=cnn_output,\n",
    "                                          merge_outputs=False)\n",
    "    rnn_output = outputs[-1] # only take value from final unrolled cell for use later\n",
    "    n_outputs = input_feature_shape[2]\n",
    "    cnn_rnn_model = mx.sym.FullyConnected(data=rnn_output,\n",
    "                                          num_hidden=n_outputs)\n",
    "\n",
    "    ## ar element\n",
    "    ar_outputs = []\n",
    "    for i in list(range(input_feature_shape[2])):\n",
    "        ar_series = mx.sym.slice_axis(data=X,\n",
    "                                      axis=2,\n",
    "                                      begin=i,\n",
    "                                      end=i+1)\n",
    "        fc_ar = mx.sym.FullyConnected(data=ar_series, num_hidden=1)\n",
    "        ar_outputs.append(fc_ar)\n",
    "    ar_model = mx.sym.concat(*ar_outputs, dim=1)\n",
    "\n",
    "    output = cnn_rnn_model + ar_model\n",
    "    loss_grad = mx.sym.LinearRegressionOutput(data=output, label=Y)\n",
    "    return (loss_grad,\n",
    "            [v.name for v in iter_train.provide_data],\n",
    "            [v.name for v in iter_train.provide_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## TRAINING ##\n",
    "################\n",
    "\n",
    "def train(symbol, iter_train, valid_iter, iter_test,\n",
    "          data_names, label_names,\n",
    "          save_dir, gpu):\n",
    "    ## save training information/results \n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "    printFile = open(os.path.join(SAVE_DIR, 'log.txt'), 'w')\n",
    "    def print_to_file(msg):\n",
    "        print(msg)\n",
    "        print(msg, file = printFile, flush = True)\n",
    "    ## print_to_file(args) ## preserve configuation to enable hyperparameter optimization\n",
    "    ## archiving results header\n",
    "    print_to_file('Epoch     Training Cor     Validation Cor')\n",
    "\n",
    "\n",
    "    ## storing prior epoch's values to set an improvement threshold\n",
    "    ## terminates early if progress slow\n",
    "    buf     = RingBuffer(THRESHOLD_EPOCHS)\n",
    "    old_val = None\n",
    "\n",
    "    ## mxnet boilerplate\n",
    "    ## defaults to 1 gpu of which index is 0\n",
    "    ##devs = [mx.gpu(gpu)]\n",
    "    devs   = mx.cpu()\n",
    "    module = mx.mod.Module(symbol,\n",
    "                           data_names=data_names,\n",
    "                           label_names=label_names,\n",
    "                           context=devs)\n",
    "    module.bind(data_shapes=iter_train.provide_data,\n",
    "                label_shapes=iter_train.provide_label)\n",
    "    module.init_params(mx.initializer.Uniform(0.1))\n",
    "    module.init_optimizer(optimizer='adam',\n",
    "                          optimizer_params={'learning_rate': LR})\n",
    "\n",
    "    ## training\n",
    "    for epoch in range( N_EPOCHS):\n",
    "        iter_train.reset()\n",
    "        iter_val.reset()\n",
    "        for batch in iter_train:\n",
    "            module.forward(batch, is_train=True) # compute predictions\n",
    "            module.backward()                    # compute gradients\n",
    "            module.update()                      # update parameters\n",
    "\n",
    "        ## training results\n",
    "        train_pred  = module.predict(iter_train).asnumpy()\n",
    "        train_label = iter_train.label[0][1].asnumpy()\n",
    "        train_perf  = write_eval(train_pred, train_label,\n",
    "                                      save_dir, 'train', epoch)\n",
    "\n",
    "        ## validation results\n",
    "        val_pred  = module.predict(iter_val).asnumpy()\n",
    "        val_label = iter_val.label[0][1].asnumpy()\n",
    "        val_perf = write_eval(val_pred, val_label,\n",
    "                                   save_dir, 'valid', epoch)\n",
    "\n",
    "        print_to_file('%d         %f       %f ' % (epoch, train_perf['COR'], val_perf['COR']))\n",
    "        \n",
    "        if epoch > 0:                                # if we don't yet have measures of improvement, skip\n",
    "            buf.append(val_perf['COR'] - old_val) \n",
    "        if epoch > 2:                                # if we do have measures of improvement, check them\n",
    "            vals = buf.get()\n",
    "            # print(vals)\n",
    "            # print(COR_THRESHOLD)\n",
    "            vals = [v for v in vals if v != 0]\n",
    "            if sum([v < COR_THRESHOLD for v in vals]) == len(vals):\n",
    "                print_to_file('EARLY EXIT')\n",
    "                break\n",
    "        old_val = val_perf['COR']\n",
    "                \n",
    "    ## testing\n",
    "    test_pred  = module.predict(iter_test).asnumpy()\n",
    "    test_label = iter_test.label[0][1].asnumpy()\n",
    "    test_perf = write_eval(test_pred, test_label, save_dir, 'tst', epoch)\n",
    "    print_to_file('\\n TESTING PERFORMANCE')\n",
    "    print_to_file(test_perf)\n",
    "    printFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_eval(pred, label, save_dir, mode, epoch):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    label_df = pd.DataFrame(label)\n",
    "    pred_df.to_csv(os.path.join(save_dir, '%s_pred%d.csv'\n",
    "                                % (mode,epoch)))\n",
    "    label_df.to_csv(os.path.join(save_dir, '%s_label%d.csv'\n",
    "                                % (mode,epoch)))\n",
    "\n",
    "    return { 'COR': COR(label, pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COR(label, pred):\n",
    "    label_demeaned = label - label.mean(0)\n",
    "    label_sumsquares = np.sum(np.square(label_demeaned), 0)\n",
    "\n",
    "    pred_demeaned = pred - pred.mean(0)\n",
    "    pred_sumsquares = np.sum(np.square(pred_demeaned), 0)\n",
    "\n",
    "    cor_coef =  (\n",
    "                    np.diagonal(np.dot(label_demeaned.T, pred_demeaned)) /\n",
    "                    np.sqrt(label_sumsquares * pred_sumsquares))\n",
    "\n",
    "    return np.nanmean(cor_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Cor     Validation Cor\n",
      "0         -0.024408       -0.020793 \n",
      "1         0.019818       0.027227 \n",
      "2         0.062055       0.072213 \n",
      "3         0.102126       0.114110 \n",
      "4         0.140147       0.153272 \n",
      "5         0.176340       0.190151 \n",
      "6         0.210905       0.225124 \n",
      "7         0.243974       0.258443 \n",
      "8         0.275626       0.290272 \n",
      "9         0.305927       0.320746 \n",
      "10         0.334958       0.350010 \n",
      "11         0.362823       0.378230 \n",
      "12         0.389643       0.405578 \n",
      "13         0.415535       0.432207 \n",
      "14         0.440599       0.458234 \n",
      "15         0.464905       0.483719 \n",
      "16         0.488489       0.508667 \n",
      "17         0.511355       0.533034 \n",
      "18         0.533484       0.556740 \n",
      "19         0.554839       0.579687 \n",
      "20         0.575374       0.601772 \n",
      "21         0.595044       0.622902 \n",
      "22         0.613809       0.643004 \n",
      "23         0.631638       0.662023 \n",
      "24         0.648510       0.679929 \n",
      "25         0.664419       0.696712 \n",
      "26         0.679371       0.712381 \n",
      "27         0.693379       0.726959 \n",
      "28         0.706468       0.740480 \n",
      "29         0.718670       0.752990 \n",
      "30         0.730024       0.764540 \n",
      "31         0.740572       0.775184 \n",
      "32         0.750359       0.784981 \n",
      "33         0.759433       0.793991 \n",
      "34         0.767843       0.802272 \n",
      "35         0.775634       0.809882 \n",
      "36         0.782854       0.816875 \n",
      "37         0.789546       0.823303 \n",
      "38         0.795753       0.829216 \n",
      "39         0.801516       0.834660 \n",
      "40         0.806869       0.839677 \n",
      "41         0.811849       0.844306 \n",
      "42         0.816485       0.848581 \n",
      "EARLY EXIT\n",
      "\n",
      " TESTING PERFORMANCE\n",
      "{'COR': 0.84394103}\n"
     ]
    }
   ],
   "source": [
    "# create data iterators\n",
    "iter_train, iter_val, iter_test = prepare_iters(DATA_FILE, WIN, H, MODEL, BATCH_N)    \n",
    "\n",
    "## prepare symbols\n",
    "input_feature_shape = iter_train.provide_data[0][1]    \n",
    "X                   = mx.sym.Variable(iter_train.provide_data[0].name)\n",
    "Y                   = mx.sym.Variable(iter_train.provide_label[0].name)\n",
    "    \n",
    "# set up model\n",
    "model_dict = {\n",
    "    'fc_model'            : fc_model,\n",
    "    'rnn_model'           : rnn_model,\n",
    "    'cnn_model'           : cnn_model,\n",
    "    'simple_lstnet_model' : simple_lstnet_model\n",
    "    }\n",
    "\n",
    "model = model_dict[MODEL]\n",
    "    \n",
    "symbol, data_names, label_names = model(iter_train,\n",
    "                                        input_feature_shape, X, Y,\n",
    "                                        WIN, SZ_FILT,\n",
    "                                        N_FILT, DROP, SEASONAL_PERIOD)\n",
    "\n",
    "## train \n",
    "train(symbol, iter_train, iter_val, iter_test, data_names, label_names, SAVE_DIR, GPU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('volume_forecast_oreilly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e1d7b638fb937fb704dacac9c2a3f5633d00aff928ec7a2a2aeccd6925eb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
